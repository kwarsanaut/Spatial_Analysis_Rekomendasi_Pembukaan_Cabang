{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae652b5-73a1-40d3-9a82-d9085f733130",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçΩÔ∏è  Restaurant Location ML Training System\n",
      "==================================================\n",
      "üîÑ Loading data from Data_Final_2024_Clean.csv\n",
      "‚úÖ Data loaded successfully: (1510216, 18)\n",
      "‚úÖ All required columns present\n",
      "üìä Data overview:\n",
      "   - Unique branches: 1990\n",
      "   - Categories: 23\n",
      "   - Subdistricts: 65\n",
      "\n",
      "üöÄ Starting model training...\n",
      "üîß Creating branch features...\n",
      "‚úÖ Branch features created: (1382727, 26)\n",
      "üìä Target variable (monthly_gtv) stats:\n",
      "   - Mean: Rp 293,694\n",
      "   - Median: Rp 52,030\n",
      "   - Min: Rp 0\n",
      "   - Max: Rp 211,781,062\n",
      "üìã Training models for 22 categories\n",
      "\n",
      "=== Training model for Fast Food ===\n",
      "üìä Results for Fast Food:\n",
      "   - Data points: 46461\n",
      "   - R¬≤ Score: 0.995\n",
      "   - MAE: Rp 4,987\n",
      "   - RMSE: Rp 28,953\n",
      "   - CV R¬≤ (5-fold): 0.905 ¬± 0.127\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Traditional food ===\n",
      "üìä Results for Traditional food:\n",
      "   - Data points: 247321\n",
      "   - R¬≤ Score: 0.989\n",
      "   - MAE: Rp 9,760\n",
      "   - RMSE: Rp 73,049\n",
      "   - CV R¬≤ (5-fold): 0.981 ¬± 0.010\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Coffee ===\n",
      "üìä Results for Coffee:\n",
      "   - Data points: 195336\n",
      "   - R¬≤ Score: 0.998\n",
      "   - MAE: Rp 8,485\n",
      "   - RMSE: Rp 68,462\n",
      "   - CV R¬≤ (5-fold): 0.998 ¬± 0.002\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Noodles ===\n",
      "üìä Results for Noodles:\n",
      "   - Data points: 19266\n",
      "   - R¬≤ Score: 0.988\n",
      "   - MAE: Rp 18,009\n",
      "   - RMSE: Rp 141,942\n",
      "   - CV R¬≤ (5-fold): 0.986 ¬± 0.014\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Bakery and Pastries ===\n",
      "üìä Results for Bakery and Pastries:\n",
      "   - Data points: 103516\n",
      "   - R¬≤ Score: 0.891\n",
      "   - MAE: Rp 10,879\n",
      "   - RMSE: Rp 270,741\n",
      "   - CV R¬≤ (5-fold): 0.982 ¬± 0.009\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Japanese Food ===\n",
      "üìä Results for Japanese Food:\n",
      "   - Data points: 205288\n",
      "   - R¬≤ Score: 0.996\n",
      "   - MAE: Rp 21,567\n",
      "   - RMSE: Rp 148,681\n",
      "   - CV R¬≤ (5-fold): 0.995 ¬± 0.002\n",
      "   - Most important feature: aov_2024\n",
      "\n",
      "=== Training model for Western ===\n",
      "üìä Results for Western:\n",
      "   - Data points: 156988\n",
      "   - R¬≤ Score: 0.993\n",
      "   - MAE: Rp 11,263\n",
      "   - RMSE: Rp 92,366\n",
      "   - CV R¬≤ (5-fold): 0.987 ¬± 0.005\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Desert ===\n",
      "üìä Results for Desert:\n",
      "   - Data points: 77821\n",
      "   - R¬≤ Score: 0.997\n",
      "   - MAE: Rp 8,195\n",
      "   - RMSE: Rp 51,044\n",
      "   - CV R¬≤ (5-fold): 0.980 ¬± 0.011\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Thai Food ===\n",
      "üìä Results for Thai Food:\n",
      "   - Data points: 21930\n",
      "   - R¬≤ Score: 0.995\n",
      "   - MAE: Rp 15,573\n",
      "   - RMSE: Rp 69,982\n",
      "   - CV R¬≤ (5-fold): 0.990 ¬± 0.006\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Chinese Food ===\n",
      "üìä Results for Chinese Food:\n",
      "   - Data points: 43308\n",
      "   - R¬≤ Score: 0.988\n",
      "   - MAE: Rp 12,260\n",
      "   - RMSE: Rp 99,803\n",
      "   - CV R¬≤ (5-fold): 0.991 ¬± 0.006\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Healthy Food ===\n",
      "üìä Results for Healthy Food:\n",
      "   - Data points: 42868\n",
      "   - R¬≤ Score: 0.984\n",
      "   - MAE: Rp 6,416\n",
      "   - RMSE: Rp 69,206\n",
      "   - CV R¬≤ (5-fold): 0.994 ¬± 0.002\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Alcoholic Beverages ===\n",
      "üìä Results for Alcoholic Beverages:\n",
      "   - Data points: 65646\n",
      "   - R¬≤ Score: 0.980\n",
      "   - MAE: Rp 41,620\n",
      "   - RMSE: Rp 526,839\n",
      "   - CV R¬≤ (5-fold): 0.975 ¬± 0.010\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Ricebowl ===\n",
      "üìä Results for Ricebowl:\n",
      "   - Data points: 36273\n",
      "   - R¬≤ Score: 0.997\n",
      "   - MAE: Rp 5,056\n",
      "   - RMSE: Rp 27,949\n",
      "   - CV R¬≤ (5-fold): 0.995 ¬± 0.003\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Tea and Beverages ===\n",
      "üìä Results for Tea and Beverages:\n",
      "   - Data points: 37574\n",
      "   - R¬≤ Score: 0.992\n",
      "   - MAE: Rp 4,322\n",
      "   - RMSE: Rp 39,682\n",
      "   - CV R¬≤ (5-fold): 0.969 ¬± 0.049\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Korean Food ===\n",
      "üìä Results for Korean Food:\n",
      "   - Data points: 36209\n",
      "   - R¬≤ Score: 0.964\n",
      "   - MAE: Rp 36,505\n",
      "   - RMSE: Rp 499,994\n",
      "   - CV R¬≤ (5-fold): 0.979 ¬± 0.008\n",
      "   - Most important feature: aov_2024\n",
      "\n",
      "=== Training model for Eastern ===\n",
      "üìä Results for Eastern:\n",
      "   - Data points: 12842\n",
      "   - R¬≤ Score: 0.960\n",
      "   - MAE: Rp 7,758\n",
      "   - RMSE: Rp 73,266\n",
      "   - CV R¬≤ (5-fold): 0.964 ¬± 0.019\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Snack ===\n",
      "üìä Results for Snack:\n",
      "   - Data points: 18104\n",
      "   - R¬≤ Score: 0.993\n",
      "   - MAE: Rp 6,941\n",
      "   - RMSE: Rp 61,624\n",
      "   - CV R¬≤ (5-fold): 0.985 ¬± 0.022\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Seafood ===\n",
      "üìä Results for Seafood:\n",
      "   - Data points: 9095\n",
      "   - R¬≤ Score: 0.988\n",
      "   - MAE: Rp 9,667\n",
      "   - RMSE: Rp 55,460\n",
      "   - CV R¬≤ (5-fold): 0.969 ¬± 0.036\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Fruit ===\n",
      "üìä Results for Fruit:\n",
      "   - Data points: 1570\n",
      "   - R¬≤ Score: 0.952\n",
      "   - MAE: Rp 83,860\n",
      "   - RMSE: Rp 402,390\n",
      "   - CV R¬≤ (5-fold): 0.875 ¬± 0.030\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Alcohol Beverages ===\n",
      "üìä Results for Alcohol Beverages:\n",
      "   - Data points: 368\n",
      "   - R¬≤ Score: 0.755\n",
      "   - MAE: Rp 251,930\n",
      "   - RMSE: Rp 897,429\n",
      "   - CV R¬≤ (5-fold): 0.403 ¬± 0.392\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Food Court ===\n",
      "üìä Results for Food Court:\n",
      "   - Data points: 4341\n",
      "   - R¬≤ Score: 0.985\n",
      "   - MAE: Rp 7,928\n",
      "   - RMSE: Rp 41,411\n",
      "   - CV R¬≤ (5-fold): 0.986 ¬± 0.012\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "=== Training model for Traditional Food ===\n",
      "üìä Results for Traditional Food:\n",
      "   - Data points: 602\n",
      "   - R¬≤ Score: 0.997\n",
      "   - MAE: Rp 5,064\n",
      "   - RMSE: Rp 11,489\n",
      "   - CV R¬≤ (5-fold): 0.980 ¬± 0.013\n",
      "   - Most important feature: estimated_daily_transactions\n",
      "\n",
      "üéØ Training Summary:\n",
      "   - Total categories trained: 22\n",
      "   - Average R¬≤ score: 0.972\n",
      "   - Average MAE: Rp 26,729\n",
      "\n",
      "üíæ Saving models to models/\n",
      "‚úÖ Models saved successfully!\n",
      "   - 22 category models\n",
      "   - Scalers and encoders\n",
      "   - Feature configurations\n",
      "\n",
      "üîÆ Example Prediction:\n",
      "üìç Location: (-6.2608, 106.7811)\n",
      "üè∑Ô∏è  Category: Coffee\n",
      "üí∞ Predicted Monthly GTV: Rp 18,225,941\n",
      "üìÖ Predicted Annual GTV: Rp 218,711,296\n",
      "\n",
      "‚úÖ Training completed successfully!\n",
      "üìÅ Models saved in: models/\n",
      "üöÄ Ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RestaurantLocationML:\n",
    "    def __init__(self, models_path=\"models\", data_file=\"Data_Final_2024_Clean.csv\"):\n",
    "        self.models_path = models_path\n",
    "        self.data_file = data_file\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.label_encoders = {}\n",
    "        self.branch_performance = None\n",
    "        self.feature_names = []\n",
    "        \n",
    "        # Jakarta Selatan boundaries\n",
    "        self.lat_bounds = (-6.4, -6.1)\n",
    "        self.lng_bounds = (106.7, 106.9)\n",
    "        \n",
    "        os.makedirs(models_path, exist_ok=True)\n",
    "    \n",
    "    def load_and_prepare_data(self):\n",
    "        \"\"\"Load dan prepare data dari CSV yang sudah di-clean\"\"\"\n",
    "        print(f\"üîÑ Loading data from {self.data_file}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(self.data_file)\n",
    "            print(f\"‚úÖ Data loaded successfully: {df.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading data: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Check required columns\n",
    "        required_cols = [\n",
    "            'branchID', 'latitude', 'longitude', 'gtv_2024', 'aov_2024', \n",
    "            'Category', 'subdistrictName', 'total_qty'\n",
    "        ]\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"‚ùå Missing required columns: {missing_cols}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"‚úÖ All required columns present\")\n",
    "        print(f\"üìä Data overview:\")\n",
    "        print(f\"   - Unique branches: {df['branchID'].nunique()}\")\n",
    "        print(f\"   - Categories: {df['Category'].nunique()}\")\n",
    "        print(f\"   - Subdistricts: {df['subdistrictName'].nunique()}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_branch_features(self, df):\n",
    "        \"\"\"Create comprehensive branch-level features\"\"\"\n",
    "        print(\"üîß Creating branch features...\")\n",
    "        \n",
    "        # Since data is already aggregated per branch (yearly), we work with it directly\n",
    "        branch_features = df.copy()\n",
    "        \n",
    "        # Calculate target variable: monthly_gtv\n",
    "        branch_features['monthly_gtv'] = branch_features['gtv_2024'] / 12\n",
    "        \n",
    "        # Create additional derived features\n",
    "        branch_features['estimated_transactions'] = branch_features['gtv_2024'] / branch_features['aov_2024']\n",
    "        branch_features['estimated_daily_transactions'] = branch_features['estimated_transactions'] / 365\n",
    "        branch_features['revenue_per_transaction'] = branch_features['gtv_2024'] / branch_features['total_qty']\n",
    "        \n",
    "        # Performance indicators\n",
    "        branch_features['high_value_customer'] = (branch_features['aov_2024'] > branch_features['aov_2024'].median()).astype(int)\n",
    "        branch_features['high_volume_branch'] = (branch_features['total_qty'] > branch_features['total_qty'].median()).astype(int)\n",
    "        \n",
    "        # Geographic encoding\n",
    "        le_subdistrict = LabelEncoder()\n",
    "        le_category = LabelEncoder()\n",
    "        \n",
    "        branch_features['subdistrict_encoded'] = le_subdistrict.fit_transform(branch_features['subdistrictName'])\n",
    "        branch_features['category_encoded'] = le_category.fit_transform(branch_features['Category'])\n",
    "        \n",
    "        # Store encoders\n",
    "        self.label_encoders['subdistrict'] = le_subdistrict\n",
    "        self.label_encoders['category'] = le_category\n",
    "        \n",
    "        # Clean invalid data\n",
    "        branch_features = branch_features[\n",
    "            (branch_features['latitude'] != 0) & \n",
    "            (branch_features['longitude'] != 0) &\n",
    "            (branch_features['gtv_2024'] > 0) & \n",
    "            (branch_features['aov_2024'] > 0) &\n",
    "            (branch_features['monthly_gtv'] > 0)\n",
    "        ]\n",
    "        \n",
    "        # Filter to Jakarta Selatan coordinates\n",
    "        branch_features = branch_features[\n",
    "            (branch_features['latitude'] >= self.lat_bounds[0]) & \n",
    "            (branch_features['latitude'] <= self.lat_bounds[1]) &\n",
    "            (branch_features['longitude'] >= self.lng_bounds[0]) & \n",
    "            (branch_features['longitude'] <= self.lng_bounds[1])\n",
    "        ]\n",
    "        \n",
    "        print(f\"‚úÖ Branch features created: {branch_features.shape}\")\n",
    "        print(f\"üìä Target variable (monthly_gtv) stats:\")\n",
    "        print(f\"   - Mean: Rp {branch_features['monthly_gtv'].mean():,.0f}\")\n",
    "        print(f\"   - Median: Rp {branch_features['monthly_gtv'].median():,.0f}\")\n",
    "        print(f\"   - Min: Rp {branch_features['monthly_gtv'].min():,.0f}\")\n",
    "        print(f\"   - Max: Rp {branch_features['monthly_gtv'].max():,.0f}\")\n",
    "        \n",
    "        return branch_features\n",
    "    \n",
    "    def train_models(self, df):\n",
    "        \"\"\"Train RandomForest models per category\"\"\"\n",
    "        print(\"\\nüöÄ Starting model training...\")\n",
    "        \n",
    "        branch_features = self.create_branch_features(df)\n",
    "        \n",
    "        if branch_features is None or len(branch_features) == 0:\n",
    "            print(\"‚ùå No valid data for training\")\n",
    "            return False\n",
    "        \n",
    "        # Define feature columns (exclude target and identifier columns)\n",
    "        feature_cols = [\n",
    "            'latitude', 'longitude', 'aov_2024',\n",
    "            'estimated_daily_transactions', 'revenue_per_transaction',\n",
    "            'high_value_customer', 'high_volume_branch',\n",
    "            'subdistrict_encoded'\n",
    "        ]\n",
    "        \n",
    "        self.feature_names = feature_cols\n",
    "        \n",
    "        # Get unique categories\n",
    "        categories = branch_features['Category'].unique()\n",
    "        print(f\"üìã Training models for {len(categories)} categories\")\n",
    "        \n",
    "        training_results = {}\n",
    "        \n",
    "        for category in categories:\n",
    "            print(f\"\\n=== Training model for {category} ===\")\n",
    "            \n",
    "            # Filter data for this category\n",
    "            cat_data = branch_features[branch_features['Category'] == category].copy()\n",
    "            \n",
    "            if len(cat_data) < 4:\n",
    "                print(f\"‚ö†Ô∏è  Skipping {category}: insufficient data ({len(cat_data)} records)\")\n",
    "                continue\n",
    "            \n",
    "            # Prepare features and target\n",
    "            X = cat_data[feature_cols].copy()\n",
    "            y = cat_data['monthly_gtv']\n",
    "            \n",
    "            # Check for missing values\n",
    "            if X.isnull().any().any():\n",
    "                print(f\"‚ö†Ô∏è  Found missing values in features for {category}\")\n",
    "                X = X.fillna(X.median())\n",
    "            \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            # Split data\n",
    "            if len(cat_data) < 20:\n",
    "                # For small datasets, use smaller test size\n",
    "                test_size = 0.1\n",
    "            else:\n",
    "                test_size = 0.2\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_scaled, y, test_size=test_size, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Train Random Forest model\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate model\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            \n",
    "            # Cross-validation for more robust evaluation\n",
    "            if len(X_train) > 10:\n",
    "                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "                cv_r2_mean = cv_scores.mean()\n",
    "                cv_r2_std = cv_scores.std()\n",
    "            else:\n",
    "                cv_r2_mean = cv_r2_std = 0\n",
    "            \n",
    "            # Feature importance\n",
    "            feature_importance = dict(zip(feature_cols, model.feature_importances_))\n",
    "            most_important_feature = max(feature_importance, key=feature_importance.get)\n",
    "            \n",
    "            # Store results\n",
    "            training_results[category] = {\n",
    "                'data_points': len(cat_data),\n",
    "                'r2_score': r2,\n",
    "                'mae': mae,\n",
    "                'rmse': rmse,\n",
    "                'cv_r2_mean': cv_r2_mean,\n",
    "                'cv_r2_std': cv_r2_std,\n",
    "                'most_important_feature': most_important_feature,\n",
    "                'feature_importance': feature_importance\n",
    "            }\n",
    "            \n",
    "            # Store model and scaler\n",
    "            self.models[category] = model\n",
    "            self.scalers[category] = scaler\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"üìä Results for {category}:\")\n",
    "            print(f\"   - Data points: {len(cat_data)}\")\n",
    "            print(f\"   - R¬≤ Score: {r2:.3f}\")\n",
    "            print(f\"   - MAE: Rp {mae:,.0f}\")\n",
    "            print(f\"   - RMSE: Rp {rmse:,.0f}\")\n",
    "            if cv_r2_mean > 0:\n",
    "                print(f\"   - CV R¬≤ (5-fold): {cv_r2_mean:.3f} ¬± {cv_r2_std:.3f}\")\n",
    "            print(f\"   - Most important feature: {most_important_feature}\")\n",
    "        \n",
    "        # Store branch performance data\n",
    "        self.branch_performance = branch_features\n",
    "        \n",
    "        # Print overall summary\n",
    "        print(f\"\\nüéØ Training Summary:\")\n",
    "        print(f\"   - Total categories trained: {len(self.models)}\")\n",
    "        print(f\"   - Average R¬≤ score: {np.mean([r['r2_score'] for r in training_results.values()]):.3f}\")\n",
    "        print(f\"   - Average MAE: Rp {np.mean([r['mae'] for r in training_results.values()]):,.0f}\")\n",
    "        \n",
    "        return training_results\n",
    "    \n",
    "    def predict_location_performance(self, latitude, longitude, category, aov_estimate=None):\n",
    "        \"\"\"Predict monthly GTV for a given location and category\"\"\"\n",
    "        if category not in self.models:\n",
    "            available_categories = list(self.models.keys())\n",
    "            print(f\"‚ùå Model not available for category '{category}'\")\n",
    "            print(f\"Available categories: {available_categories}\")\n",
    "            return None\n",
    "        \n",
    "        # Encode subdistrict (use most common if unknown)\n",
    "        subdistrict_encoded = 0  # Default encoding\n",
    "        \n",
    "        # Use provided AOV or category average\n",
    "        if aov_estimate is None:\n",
    "            if self.branch_performance is not None:\n",
    "                cat_data = self.branch_performance[self.branch_performance['Category'] == category]\n",
    "                aov_estimate = cat_data['aov_2024'].median() if len(cat_data) > 0 else 75000\n",
    "            else:\n",
    "                aov_estimate = 75000  # Default AOV\n",
    "        \n",
    "        # Calculate derived features (use reasonable defaults)\n",
    "        estimated_daily_transactions = 10  # Default assumption\n",
    "        revenue_per_transaction = aov_estimate * 1.2  # AOV + markup\n",
    "        high_value_customer = 1 if aov_estimate > 100000 else 0\n",
    "        high_volume_branch = 0  # Conservative assumption for new location\n",
    "        \n",
    "        # Create feature vector\n",
    "        features = np.array([[\n",
    "            latitude,\n",
    "            longitude,\n",
    "            aov_estimate,\n",
    "            estimated_daily_transactions,\n",
    "            revenue_per_transaction,\n",
    "            high_value_customer,\n",
    "            high_volume_branch,\n",
    "            subdistrict_encoded\n",
    "        ]])\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = self.scalers[category]\n",
    "        features_scaled = scaler.transform(features)\n",
    "        \n",
    "        # Make prediction\n",
    "        model = self.models[category]\n",
    "        predicted_monthly_gtv = model.predict(features_scaled)[0]\n",
    "        \n",
    "        return {\n",
    "            'category': category,\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude,\n",
    "            'predicted_monthly_gtv': predicted_monthly_gtv,\n",
    "            'predicted_annual_gtv': predicted_monthly_gtv * 12,\n",
    "            'input_aov': aov_estimate\n",
    "        }\n",
    "    \n",
    "    def save_models(self):\n",
    "        \"\"\"Save all trained models and encoders\"\"\"\n",
    "        print(f\"\\nüíæ Saving models to {self.models_path}/\")\n",
    "        \n",
    "        # Save models\n",
    "        for category, model in self.models.items():\n",
    "            filename = f\"{category.replace(' ', '_').replace('/', '_')}_model.pkl\"\n",
    "            filepath = os.path.join(self.models_path, filename)\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "        \n",
    "        # Save scalers\n",
    "        scalers_file = os.path.join(self.models_path, 'scalers.pkl')\n",
    "        with open(scalers_file, 'wb') as f:\n",
    "            pickle.dump(self.scalers, f)\n",
    "        \n",
    "        # Save label encoders\n",
    "        encoders_file = os.path.join(self.models_path, 'label_encoders.pkl')\n",
    "        with open(encoders_file, 'wb') as f:\n",
    "            pickle.dump(self.label_encoders, f)\n",
    "        \n",
    "        # Save feature names\n",
    "        features_file = os.path.join(self.models_path, 'feature_names.pkl')\n",
    "        with open(features_file, 'wb') as f:\n",
    "            pickle.dump(self.feature_names, f)\n",
    "        \n",
    "        # Save branch performance data\n",
    "        if self.branch_performance is not None:\n",
    "            performance_file = os.path.join(self.models_path, 'branch_performance.pkl')\n",
    "            with open(performance_file, 'wb') as f:\n",
    "                pickle.dump(self.branch_performance, f)\n",
    "        \n",
    "        print(f\"‚úÖ Models saved successfully!\")\n",
    "        print(f\"   - {len(self.models)} category models\")\n",
    "        print(f\"   - Scalers and encoders\")\n",
    "        print(f\"   - Feature configurations\")\n",
    "    \n",
    "    def load_models(self):\n",
    "        \"\"\"Load previously trained models\"\"\"\n",
    "        print(f\"üìÇ Loading models from {self.models_path}/\")\n",
    "        \n",
    "        try:\n",
    "            # Load scalers\n",
    "            scalers_file = os.path.join(self.models_path, 'scalers.pkl')\n",
    "            with open(scalers_file, 'rb') as f:\n",
    "                self.scalers = pickle.load(f)\n",
    "            \n",
    "            # Load label encoders\n",
    "            encoders_file = os.path.join(self.models_path, 'label_encoders.pkl')\n",
    "            with open(encoders_file, 'rb') as f:\n",
    "                self.label_encoders = pickle.load(f)\n",
    "            \n",
    "            # Load feature names\n",
    "            features_file = os.path.join(self.models_path, 'feature_names.pkl')\n",
    "            with open(features_file, 'rb') as f:\n",
    "                self.feature_names = pickle.load(f)\n",
    "            \n",
    "            # Load branch performance\n",
    "            performance_file = os.path.join(self.models_path, 'branch_performance.pkl')\n",
    "            if os.path.exists(performance_file):\n",
    "                with open(performance_file, 'rb') as f:\n",
    "                    self.branch_performance = pickle.load(f)\n",
    "            \n",
    "            # Load models\n",
    "            model_files = [f for f in os.listdir(self.models_path) if f.endswith('_model.pkl')]\n",
    "            for model_file in model_files:\n",
    "                category = model_file.replace('_model.pkl', '').replace('_', ' ')\n",
    "                filepath = os.path.join(self.models_path, model_file)\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    self.models[category] = pickle.load(f)\n",
    "            \n",
    "            print(f\"‚úÖ Models loaded successfully!\")\n",
    "            print(f\"   - {len(self.models)} category models loaded\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading models: {e}\")\n",
    "            return False\n",
    "\n",
    "# Example usage and training script\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üçΩÔ∏è  Restaurant Location ML Training System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize the ML system\n",
    "    ml_system = RestaurantLocationML(\n",
    "        models_path=\"models\",\n",
    "        data_file=\"Data_Final_2024_Clean.csv\"\n",
    "    )\n",
    "    \n",
    "    # Load and prepare data\n",
    "    df = ml_system.load_and_prepare_data()\n",
    "    if df is None:\n",
    "        print(\"‚ùå Failed to load data. Exiting...\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Train models\n",
    "    training_results = ml_system.train_models(df)\n",
    "    if not training_results:\n",
    "        print(\"‚ùå Training failed. Exiting...\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Save trained models\n",
    "    ml_system.save_models()\n",
    "    \n",
    "    # Example prediction\n",
    "    print(\"\\nüîÆ Example Prediction:\")\n",
    "    example_prediction = ml_system.predict_location_performance(\n",
    "        latitude=-6.2608,  # Kebayoran area\n",
    "        longitude=106.7811,\n",
    "        category=\"Coffee\",  # Change to a category in your data\n",
    "        aov_estimate=85000\n",
    "    )\n",
    "    \n",
    "    if example_prediction:\n",
    "        print(f\"üìç Location: ({example_prediction['latitude']}, {example_prediction['longitude']})\")\n",
    "        print(f\"üè∑Ô∏è  Category: {example_prediction['category']}\")\n",
    "        print(f\"üí∞ Predicted Monthly GTV: Rp {example_prediction['predicted_monthly_gtv']:,.0f}\")\n",
    "        print(f\"üìÖ Predicted Annual GTV: Rp {example_prediction['predicted_annual_gtv']:,.0f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "    print(f\"üìÅ Models saved in: {ml_system.models_path}/\")\n",
    "    print(\"üöÄ Ready for deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6aa533f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>menuID</th>\n",
       "      <th>SalesDate</th>\n",
       "      <th>cityName</th>\n",
       "      <th>brandName</th>\n",
       "      <th>branchID</th>\n",
       "      <th>branchName</th>\n",
       "      <th>branchCode</th>\n",
       "      <th>branchCompanyID</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>subdistrictName</th>\n",
       "      <th>companyID</th>\n",
       "      <th>companyName</th>\n",
       "      <th>companyCode</th>\n",
       "      <th>total_qty</th>\n",
       "      <th>gtv_2024</th>\n",
       "      <th>aov_2024</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1173835</td>\n",
       "      <td>2024-08-02</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Oz Lezzat</td>\n",
       "      <td>2439</td>\n",
       "      <td>Kamu Kunafa?</td>\n",
       "      <td>OZL</td>\n",
       "      <td>8560</td>\n",
       "      <td>-6.243348</td>\n",
       "      <td>106.798603</td>\n",
       "      <td>Melawai</td>\n",
       "      <td>8560</td>\n",
       "      <td>PT Dour Almadinah Almunawarah</td>\n",
       "      <td>DAW</td>\n",
       "      <td>5945.0</td>\n",
       "      <td>2.060516e+08</td>\n",
       "      <td>34659.646762</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1173828</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Oz Lezzat</td>\n",
       "      <td>2440</td>\n",
       "      <td>Kamu Kunafa Event</td>\n",
       "      <td>KKNE</td>\n",
       "      <td>8560</td>\n",
       "      <td>-6.294338</td>\n",
       "      <td>106.784689</td>\n",
       "      <td>Cilandak Barat</td>\n",
       "      <td>8560</td>\n",
       "      <td>PT Dour Almadinah Almunawarah</td>\n",
       "      <td>DAW</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1.951150e+07</td>\n",
       "      <td>52591.644205</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1413420</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Kebuli Ijab Qabul Tebet</td>\n",
       "      <td>5110</td>\n",
       "      <td>Kebuli Ijab Qabul Tebet</td>\n",
       "      <td>KIQT</td>\n",
       "      <td>3150</td>\n",
       "      <td>-6.225468</td>\n",
       "      <td>106.852420</td>\n",
       "      <td>Tebet Timur</td>\n",
       "      <td>3150</td>\n",
       "      <td>Irwan hiusnandar ( Franchise ijab qabul Tebet)</td>\n",
       "      <td>IHR</td>\n",
       "      <td>22384.0</td>\n",
       "      <td>1.383380e+09</td>\n",
       "      <td>61802.173791</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1578182</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>ISTANBUL KEBAB</td>\n",
       "      <td>7418</td>\n",
       "      <td>Istanbul Kebab &amp; Pide Turkish Pizza Kalibata</td>\n",
       "      <td>IKKB</td>\n",
       "      <td>3527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Rawa Jati</td>\n",
       "      <td>3527</td>\n",
       "      <td>PT Mustafa Kuliner Indonesia</td>\n",
       "      <td>MFKI</td>\n",
       "      <td>5107.0</td>\n",
       "      <td>1.006050e+08</td>\n",
       "      <td>19699.441747</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1578182</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>ISTANBUL KEBAB</td>\n",
       "      <td>7447</td>\n",
       "      <td>Lidah Mertua X Pide X Kebab Moh. Kahfi Jagakarsa</td>\n",
       "      <td>JAGA</td>\n",
       "      <td>3527</td>\n",
       "      <td>-6.322386</td>\n",
       "      <td>106.811174</td>\n",
       "      <td>Jagakarsa</td>\n",
       "      <td>3527</td>\n",
       "      <td>PT Mustafa Kuliner Indonesia</td>\n",
       "      <td>MFKI</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2.108558e+07</td>\n",
       "      <td>10670.840081</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1578183</td>\n",
       "      <td>2024-06-14</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>ISTANBUL KEBAB</td>\n",
       "      <td>7450</td>\n",
       "      <td>Istanbul Kebab &amp; Pide Turkish Pizza Cidodol</td>\n",
       "      <td>CKBLM</td>\n",
       "      <td>3527</td>\n",
       "      <td>-6.228848</td>\n",
       "      <td>106.772147</td>\n",
       "      <td>Grogol Selatan</td>\n",
       "      <td>3527</td>\n",
       "      <td>PT Mustafa Kuliner Indonesia</td>\n",
       "      <td>MFKI</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>3.522238e+07</td>\n",
       "      <td>17664.182548</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2216075</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Almaz Fried Chicken</td>\n",
       "      <td>18311</td>\n",
       "      <td>Almaz Fried Chicken - Jagakarsa</td>\n",
       "      <td>AZFCS</td>\n",
       "      <td>8695</td>\n",
       "      <td>-6.350166</td>\n",
       "      <td>106.802254</td>\n",
       "      <td>Cipedak</td>\n",
       "      <td>8695</td>\n",
       "      <td>Almaz Fried Chicken</td>\n",
       "      <td>AZFC</td>\n",
       "      <td>137682.0</td>\n",
       "      <td>1.052748e+09</td>\n",
       "      <td>7646.225287</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>2391967</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>EMADO'S ELITE</td>\n",
       "      <td>20974</td>\n",
       "      <td>EMADO'S ELITE</td>\n",
       "      <td>EMSB</td>\n",
       "      <td>7694</td>\n",
       "      <td>-6.224020</td>\n",
       "      <td>106.810186</td>\n",
       "      <td>Senayan</td>\n",
       "      <td>7694</td>\n",
       "      <td>PT Emados Kebab Indonesia</td>\n",
       "      <td>EKI</td>\n",
       "      <td>83768.0</td>\n",
       "      <td>3.116486e+09</td>\n",
       "      <td>37203.771217</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>2444035</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>22717</td>\n",
       "      <td>Fingers Butter Rice, Tebet</td>\n",
       "      <td>FBR01</td>\n",
       "      <td>2782</td>\n",
       "      <td>-6.240972</td>\n",
       "      <td>106.850233</td>\n",
       "      <td>Tebet Barat</td>\n",
       "      <td>2782</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>FBR</td>\n",
       "      <td>15166.0</td>\n",
       "      <td>6.232600e+08</td>\n",
       "      <td>41095.872346</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>2444035</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>22722</td>\n",
       "      <td>Fingers Butter Rice, Cipete Utara</td>\n",
       "      <td>FBR06</td>\n",
       "      <td>2782</td>\n",
       "      <td>-6.265465</td>\n",
       "      <td>106.804249</td>\n",
       "      <td>Cipete Utara</td>\n",
       "      <td>2782</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>FBR</td>\n",
       "      <td>15986.0</td>\n",
       "      <td>6.707740e+08</td>\n",
       "      <td>41960.090079</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>2444035</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>22726</td>\n",
       "      <td>Fingers Butter Rice, Mampang Prapatan</td>\n",
       "      <td>FBR10</td>\n",
       "      <td>2782</td>\n",
       "      <td>-6.251474</td>\n",
       "      <td>106.831062</td>\n",
       "      <td>Tegal Parang</td>\n",
       "      <td>2782</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>FBR</td>\n",
       "      <td>10542.0</td>\n",
       "      <td>4.005355e+08</td>\n",
       "      <td>37994.261051</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>2444034</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>22728</td>\n",
       "      <td>Fingers Butter Rice, Bintaro</td>\n",
       "      <td>FBRB</td>\n",
       "      <td>2782</td>\n",
       "      <td>-6.269728</td>\n",
       "      <td>106.753916</td>\n",
       "      <td>Bintaro</td>\n",
       "      <td>2782</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>FBR</td>\n",
       "      <td>9013.0</td>\n",
       "      <td>3.481775e+08</td>\n",
       "      <td>38630.589149</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>2444111</td>\n",
       "      <td>2024-12-13</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>22731</td>\n",
       "      <td>Fingers Butter Rice, Permata Hijau</td>\n",
       "      <td>FBR13</td>\n",
       "      <td>2782</td>\n",
       "      <td>-6.221120</td>\n",
       "      <td>106.784429</td>\n",
       "      <td>Grogol Utara</td>\n",
       "      <td>2782</td>\n",
       "      <td>Fingers Butter Rice</td>\n",
       "      <td>FBR</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1.863650e+07</td>\n",
       "      <td>43140.046296</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>2661591</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>The Indian Flame</td>\n",
       "      <td>24440</td>\n",
       "      <td>The Indian Flame Bellezza Shopping Arcade</td>\n",
       "      <td>TIFB</td>\n",
       "      <td>2798</td>\n",
       "      <td>-6.220471</td>\n",
       "      <td>106.782250</td>\n",
       "      <td>Grogol Utara</td>\n",
       "      <td>2798</td>\n",
       "      <td>PT Sequoia International Cuisine</td>\n",
       "      <td>IND</td>\n",
       "      <td>58951.0</td>\n",
       "      <td>5.044857e+09</td>\n",
       "      <td>85577.118682</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2811895</td>\n",
       "      <td>2024-06-19</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Little Beirut</td>\n",
       "      <td>26762</td>\n",
       "      <td>Little Beirut Kalibata</td>\n",
       "      <td>LBCS</td>\n",
       "      <td>8353</td>\n",
       "      <td>-6.254836</td>\n",
       "      <td>106.842723</td>\n",
       "      <td>Duren Tiga</td>\n",
       "      <td>8353</td>\n",
       "      <td>Muhammad Nadiv Abdullah A</td>\n",
       "      <td>MDV</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.488400e+06</td>\n",
       "      <td>29724.503351</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>3311516</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>KEBULI ABUYA</td>\n",
       "      <td>35202</td>\n",
       "      <td>KEBULI ABUYA TANJUNG BARAT</td>\n",
       "      <td>KATBR</td>\n",
       "      <td>5373</td>\n",
       "      <td>-6.295894</td>\n",
       "      <td>106.843291</td>\n",
       "      <td>Pejaten Timur</td>\n",
       "      <td>5373</td>\n",
       "      <td>PT. Abuya Berkah Indonesia Makmur</td>\n",
       "      <td>ABIM</td>\n",
       "      <td>28324.0</td>\n",
       "      <td>5.722335e+08</td>\n",
       "      <td>20203.131620</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>3311517</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>KEBULI ABUYA</td>\n",
       "      <td>35230</td>\n",
       "      <td>KEBULI ABUYA TIMBUL</td>\n",
       "      <td>KATML</td>\n",
       "      <td>5373</td>\n",
       "      <td>-6.351066</td>\n",
       "      <td>106.808681</td>\n",
       "      <td>Cipedak</td>\n",
       "      <td>5373</td>\n",
       "      <td>PT. Abuya Berkah Indonesia Makmur</td>\n",
       "      <td>ABIM</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>2.179700e+07</td>\n",
       "      <td>17564.061241</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>3311516</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>KEBULI ABUYA</td>\n",
       "      <td>35276</td>\n",
       "      <td>KEBULI ABUYA AMPERA</td>\n",
       "      <td>KAAP</td>\n",
       "      <td>5373</td>\n",
       "      <td>-6.286137</td>\n",
       "      <td>106.818882</td>\n",
       "      <td>Ragunan</td>\n",
       "      <td>5373</td>\n",
       "      <td>PT. Abuya Berkah Indonesia Makmur</td>\n",
       "      <td>ABIM</td>\n",
       "      <td>41175.0</td>\n",
       "      <td>8.900540e+08</td>\n",
       "      <td>21616.369156</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>3311516</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>KEBULI ABUYA</td>\n",
       "      <td>35277</td>\n",
       "      <td>KEBULI ABUYA VETERAN</td>\n",
       "      <td>KAVT</td>\n",
       "      <td>5373</td>\n",
       "      <td>-6.260517</td>\n",
       "      <td>106.767319</td>\n",
       "      <td>Bintaro</td>\n",
       "      <td>5373</td>\n",
       "      <td>PT. Abuya Berkah Indonesia Makmur</td>\n",
       "      <td>ABIM</td>\n",
       "      <td>41510.0</td>\n",
       "      <td>8.410578e+08</td>\n",
       "      <td>20261.569501</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>3311516</td>\n",
       "      <td>2024-09-15</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>KEBULI ABUYA</td>\n",
       "      <td>35340</td>\n",
       "      <td>KEBULI ABUYA PETUKANGAN</td>\n",
       "      <td>KAPTK</td>\n",
       "      <td>5373</td>\n",
       "      <td>-6.234922</td>\n",
       "      <td>106.744429</td>\n",
       "      <td>Petukangan Utara</td>\n",
       "      <td>5373</td>\n",
       "      <td>PT. Abuya Berkah Indonesia Makmur</td>\n",
       "      <td>ABIM</td>\n",
       "      <td>11836.0</td>\n",
       "      <td>2.070478e+08</td>\n",
       "      <td>17493.050862</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>3331357</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Kebuli Mister Ajib</td>\n",
       "      <td>35739</td>\n",
       "      <td>Kebuli Mister Ajib Cilandak</td>\n",
       "      <td>KMAC</td>\n",
       "      <td>1111</td>\n",
       "      <td>-6.299520</td>\n",
       "      <td>106.814356</td>\n",
       "      <td>Cilandak Barat</td>\n",
       "      <td>1111</td>\n",
       "      <td>Kebuli Mister Ajib</td>\n",
       "      <td>AJIB</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>2.367120e+08</td>\n",
       "      <td>87509.057301</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>3331784</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>KEBULI AL-KHALID</td>\n",
       "      <td>35763</td>\n",
       "      <td>KEBULI AL-KHALID SEMANGGI</td>\n",
       "      <td>KAM</td>\n",
       "      <td>5855</td>\n",
       "      <td>-6.249314</td>\n",
       "      <td>106.826561</td>\n",
       "      <td>Mampang Prapatan</td>\n",
       "      <td>5855</td>\n",
       "      <td>Kebuli Al-Khalid</td>\n",
       "      <td>AKD</td>\n",
       "      <td>18383.0</td>\n",
       "      <td>9.685207e+08</td>\n",
       "      <td>52685.669477</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>3331784</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>KEBULI AL-KHALID</td>\n",
       "      <td>35764</td>\n",
       "      <td>KEBULI AL-KHALID KELAPA GADING</td>\n",
       "      <td>KAN</td>\n",
       "      <td>5855</td>\n",
       "      <td>-6.216129</td>\n",
       "      <td>106.818239</td>\n",
       "      <td>Karet Semanggi</td>\n",
       "      <td>5855</td>\n",
       "      <td>Kebuli Al-Khalid</td>\n",
       "      <td>AKD</td>\n",
       "      <td>44166.0</td>\n",
       "      <td>2.309885e+09</td>\n",
       "      <td>52300.073745</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>4341120</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Maharaj Gatsu</td>\n",
       "      <td>44632</td>\n",
       "      <td>Maharaj Gatsu</td>\n",
       "      <td>MHG</td>\n",
       "      <td>6549</td>\n",
       "      <td>-6.225481</td>\n",
       "      <td>106.821877</td>\n",
       "      <td>Karet Semanggi</td>\n",
       "      <td>6549</td>\n",
       "      <td>Maharaj Gatsu</td>\n",
       "      <td>MHR</td>\n",
       "      <td>12619.0</td>\n",
       "      <td>2.874696e+08</td>\n",
       "      <td>22780.692606</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>4786013</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>THE HALAL GUYS</td>\n",
       "      <td>50535</td>\n",
       "      <td>The Halal Guys PIM 2</td>\n",
       "      <td>HGP</td>\n",
       "      <td>4267</td>\n",
       "      <td>-6.264388</td>\n",
       "      <td>106.780823</td>\n",
       "      <td>Pondok Pinang</td>\n",
       "      <td>4267</td>\n",
       "      <td>PT Yorkindo Boga Utama</td>\n",
       "      <td>YBU</td>\n",
       "      <td>120410.0</td>\n",
       "      <td>3.588139e+09</td>\n",
       "      <td>29799.343209</td>\n",
       "      <td>Eastern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       menuID   SalesDate         cityName                brandName  branchID  \\\n",
       "124   1173835  2024-08-02  Jakarta Selatan                Oz Lezzat      2439   \n",
       "125   1173828  2024-10-02  Jakarta Selatan                Oz Lezzat      2440   \n",
       "233   1413420  2024-01-02  Jakarta Selatan  Kebuli Ijab Qabul Tebet      5110   \n",
       "346   1578182  2024-01-01  Jakarta Selatan           ISTANBUL KEBAB      7418   \n",
       "347   1578182  2024-11-03  Jakarta Selatan           ISTANBUL KEBAB      7447   \n",
       "348   1578183  2024-06-14  Jakarta Selatan           ISTANBUL KEBAB      7450   \n",
       "722   2216075  2024-11-10  Jakarta Selatan      Almaz Fried Chicken     18311   \n",
       "808   2391967  2024-03-14  Jakarta Selatan            EMADO'S ELITE     20974   \n",
       "838   2444035  2024-01-01  Jakarta Selatan      Fingers Butter Rice     22717   \n",
       "839   2444035  2024-01-01  Jakarta Selatan      Fingers Butter Rice     22722   \n",
       "840   2444035  2024-01-01  Jakarta Selatan      Fingers Butter Rice     22726   \n",
       "841   2444034  2024-01-01  Jakarta Selatan      Fingers Butter Rice     22728   \n",
       "842   2444111  2024-12-13  Jakarta Selatan      Fingers Butter Rice     22731   \n",
       "909   2661591  2024-01-01  Jakarta Selatan         The Indian Flame     24440   \n",
       "1000  2811895  2024-06-19  Jakarta Selatan            Little Beirut     26762   \n",
       "1298  3311516  2024-01-01  Jakarta Selatan             KEBULI ABUYA     35202   \n",
       "1299  3311517  2024-01-03  Jakarta Selatan             KEBULI ABUYA     35230   \n",
       "1300  3311516  2024-01-01  Jakarta Selatan             KEBULI ABUYA     35276   \n",
       "1301  3311516  2024-01-01  Jakarta Selatan             KEBULI ABUYA     35277   \n",
       "1302  3311516  2024-09-15  Jakarta Selatan             KEBULI ABUYA     35340   \n",
       "1343  3331357  2024-01-03  Jakarta Selatan       Kebuli Mister Ajib     35739   \n",
       "1344  3331784  2024-01-01  Jakarta Selatan         KEBULI AL-KHALID     35763   \n",
       "1345  3331784  2024-01-01  Jakarta Selatan         KEBULI AL-KHALID     35764   \n",
       "1682  4341120  2024-01-02  Jakarta Selatan            Maharaj Gatsu     44632   \n",
       "1904  4786013  2024-01-01  Jakarta Selatan           THE HALAL GUYS     50535   \n",
       "\n",
       "                                            branchName branchCode  \\\n",
       "124                                       Kamu Kunafa?        OZL   \n",
       "125                                  Kamu Kunafa Event       KKNE   \n",
       "233                            Kebuli Ijab Qabul Tebet       KIQT   \n",
       "346       Istanbul Kebab & Pide Turkish Pizza Kalibata       IKKB   \n",
       "347   Lidah Mertua X Pide X Kebab Moh. Kahfi Jagakarsa       JAGA   \n",
       "348        Istanbul Kebab & Pide Turkish Pizza Cidodol      CKBLM   \n",
       "722                    Almaz Fried Chicken - Jagakarsa      AZFCS   \n",
       "808                                      EMADO'S ELITE       EMSB   \n",
       "838                         Fingers Butter Rice, Tebet      FBR01   \n",
       "839                  Fingers Butter Rice, Cipete Utara      FBR06   \n",
       "840              Fingers Butter Rice, Mampang Prapatan      FBR10   \n",
       "841                       Fingers Butter Rice, Bintaro       FBRB   \n",
       "842                 Fingers Butter Rice, Permata Hijau      FBR13   \n",
       "909          The Indian Flame Bellezza Shopping Arcade       TIFB   \n",
       "1000                            Little Beirut Kalibata       LBCS   \n",
       "1298                        KEBULI ABUYA TANJUNG BARAT      KATBR   \n",
       "1299                               KEBULI ABUYA TIMBUL      KATML   \n",
       "1300                               KEBULI ABUYA AMPERA       KAAP   \n",
       "1301                              KEBULI ABUYA VETERAN       KAVT   \n",
       "1302                           KEBULI ABUYA PETUKANGAN      KAPTK   \n",
       "1343                       Kebuli Mister Ajib Cilandak       KMAC   \n",
       "1344                         KEBULI AL-KHALID SEMANGGI        KAM   \n",
       "1345                    KEBULI AL-KHALID KELAPA GADING        KAN   \n",
       "1682                                     Maharaj Gatsu        MHG   \n",
       "1904                              The Halal Guys PIM 2        HGP   \n",
       "\n",
       "      branchCompanyID  latitude   longitude   subdistrictName  companyID  \\\n",
       "124              8560 -6.243348  106.798603           Melawai       8560   \n",
       "125              8560 -6.294338  106.784689    Cilandak Barat       8560   \n",
       "233              3150 -6.225468  106.852420       Tebet Timur       3150   \n",
       "346              3527  0.000000    0.000000         Rawa Jati       3527   \n",
       "347              3527 -6.322386  106.811174         Jagakarsa       3527   \n",
       "348              3527 -6.228848  106.772147    Grogol Selatan       3527   \n",
       "722              8695 -6.350166  106.802254           Cipedak       8695   \n",
       "808              7694 -6.224020  106.810186           Senayan       7694   \n",
       "838              2782 -6.240972  106.850233       Tebet Barat       2782   \n",
       "839              2782 -6.265465  106.804249      Cipete Utara       2782   \n",
       "840              2782 -6.251474  106.831062      Tegal Parang       2782   \n",
       "841              2782 -6.269728  106.753916           Bintaro       2782   \n",
       "842              2782 -6.221120  106.784429      Grogol Utara       2782   \n",
       "909              2798 -6.220471  106.782250      Grogol Utara       2798   \n",
       "1000             8353 -6.254836  106.842723        Duren Tiga       8353   \n",
       "1298             5373 -6.295894  106.843291     Pejaten Timur       5373   \n",
       "1299             5373 -6.351066  106.808681           Cipedak       5373   \n",
       "1300             5373 -6.286137  106.818882           Ragunan       5373   \n",
       "1301             5373 -6.260517  106.767319           Bintaro       5373   \n",
       "1302             5373 -6.234922  106.744429  Petukangan Utara       5373   \n",
       "1343             1111 -6.299520  106.814356    Cilandak Barat       1111   \n",
       "1344             5855 -6.249314  106.826561  Mampang Prapatan       5855   \n",
       "1345             5855 -6.216129  106.818239    Karet Semanggi       5855   \n",
       "1682             6549 -6.225481  106.821877    Karet Semanggi       6549   \n",
       "1904             4267 -6.264388  106.780823     Pondok Pinang       4267   \n",
       "\n",
       "                                         companyName companyCode  total_qty  \\\n",
       "124                    PT Dour Almadinah Almunawarah         DAW     5945.0   \n",
       "125                    PT Dour Almadinah Almunawarah         DAW      371.0   \n",
       "233   Irwan hiusnandar ( Franchise ijab qabul Tebet)         IHR    22384.0   \n",
       "346                     PT Mustafa Kuliner Indonesia        MFKI     5107.0   \n",
       "347                     PT Mustafa Kuliner Indonesia        MFKI     1976.0   \n",
       "348                     PT Mustafa Kuliner Indonesia        MFKI     1994.0   \n",
       "722                              Almaz Fried Chicken        AZFC   137682.0   \n",
       "808                        PT Emados Kebab Indonesia         EKI    83768.0   \n",
       "838                              Fingers Butter Rice         FBR    15166.0   \n",
       "839                              Fingers Butter Rice         FBR    15986.0   \n",
       "840                              Fingers Butter Rice         FBR    10542.0   \n",
       "841                              Fingers Butter Rice         FBR     9013.0   \n",
       "842                              Fingers Butter Rice         FBR      432.0   \n",
       "909                 PT Sequoia International Cuisine         IND    58951.0   \n",
       "1000                       Muhammad Nadiv Abdullah A         MDV      151.0   \n",
       "1298               PT. Abuya Berkah Indonesia Makmur        ABIM    28324.0   \n",
       "1299               PT. Abuya Berkah Indonesia Makmur        ABIM     1241.0   \n",
       "1300               PT. Abuya Berkah Indonesia Makmur        ABIM    41175.0   \n",
       "1301               PT. Abuya Berkah Indonesia Makmur        ABIM    41510.0   \n",
       "1302               PT. Abuya Berkah Indonesia Makmur        ABIM    11836.0   \n",
       "1343                              Kebuli Mister Ajib        AJIB     2705.0   \n",
       "1344                                Kebuli Al-Khalid         AKD    18383.0   \n",
       "1345                                Kebuli Al-Khalid         AKD    44166.0   \n",
       "1682                                   Maharaj Gatsu         MHR    12619.0   \n",
       "1904                          PT Yorkindo Boga Utama         YBU   120410.0   \n",
       "\n",
       "          gtv_2024      aov_2024 Category  \n",
       "124   2.060516e+08  34659.646762  Eastern  \n",
       "125   1.951150e+07  52591.644205  Eastern  \n",
       "233   1.383380e+09  61802.173791  Eastern  \n",
       "346   1.006050e+08  19699.441747  Eastern  \n",
       "347   2.108558e+07  10670.840081  Eastern  \n",
       "348   3.522238e+07  17664.182548  Eastern  \n",
       "722   1.052748e+09   7646.225287  Eastern  \n",
       "808   3.116486e+09  37203.771217  Eastern  \n",
       "838   6.232600e+08  41095.872346  Eastern  \n",
       "839   6.707740e+08  41960.090079  Eastern  \n",
       "840   4.005355e+08  37994.261051  Eastern  \n",
       "841   3.481775e+08  38630.589149  Eastern  \n",
       "842   1.863650e+07  43140.046296  Eastern  \n",
       "909   5.044857e+09  85577.118682  Eastern  \n",
       "1000  4.488400e+06  29724.503351  Eastern  \n",
       "1298  5.722335e+08  20203.131620  Eastern  \n",
       "1299  2.179700e+07  17564.061241  Eastern  \n",
       "1300  8.900540e+08  21616.369156  Eastern  \n",
       "1301  8.410578e+08  20261.569501  Eastern  \n",
       "1302  2.070478e+08  17493.050862  Eastern  \n",
       "1343  2.367120e+08  87509.057301  Eastern  \n",
       "1344  9.685207e+08  52685.669477  Eastern  \n",
       "1345  2.309885e+09  52300.073745  Eastern  \n",
       "1682  2.874696e+08  22780.692606  Eastern  \n",
       "1904  3.588139e+09  29799.343209  Eastern  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_clean.csv\")\n",
    "df_soy = df[df[\"Category\"] == \"Eastern\"]\n",
    "df_soy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba5c3e-6d93-4ea3-82e2-f7b895e579d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 07:34:43.423 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.622 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.623 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.699 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\ESB\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-09-29 07:34:43.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.703 No runtime found, using MemoryCacheStorageManager\n",
      "2025-09-29 07:34:43.716 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.718 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.727 No runtime found, using MemoryCacheStorageManager\n",
      "2025-09-29 07:34:43.728 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.729 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.730 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.837 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.839 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.842 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.843 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.844 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.847 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.849 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.853 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.854 Session state does not function when running a script without `streamlit run`\n",
      "2025-09-29 07:34:43.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.860 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.861 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.862 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.864 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.865 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.865 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.868 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.869 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.871 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.875 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.889 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.891 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.892 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.893 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.894 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.894 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.896 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.897 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-29 07:34:43.898 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "# import folium\n",
    "# from folium import plugins\n",
    "# from streamlit_folium import st_folium\n",
    "# import os\n",
    "\n",
    "# # Page configuration\n",
    "# st.set_page_config(\n",
    "#     page_title=\"Restaurant Location ML System\",\n",
    "#     page_icon=\"üçΩÔ∏è\",\n",
    "#     layout=\"wide\",\n",
    "#     initial_sidebar_state=\"expanded\"\n",
    "# )\n",
    "\n",
    "# # Custom CSS\n",
    "# st.markdown(\"\"\"\n",
    "# <style>\n",
    "#     .main-header {\n",
    "#         font-size: 2.5rem;\n",
    "#         color: #1f77b4;\n",
    "#         text-align: center;\n",
    "#         margin-bottom: 1rem;\n",
    "#     }\n",
    "#     .metric-card {\n",
    "#         background-color: #f0f2f6;\n",
    "#         padding: 1rem;\n",
    "#         border-radius: 10px;\n",
    "#         border-left: 5px solid #1f77b4;\n",
    "#         margin: 0.5rem 0;\n",
    "#     }\n",
    "#     .location-card {\n",
    "#         background-color: #ffffff;\n",
    "#         padding: 1rem;\n",
    "#         border-radius: 8px;\n",
    "#         box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "#         margin: 0.5rem 0;\n",
    "#     }\n",
    "#     .stDataFrame {\n",
    "#         font-size: 14px;\n",
    "#     }\n",
    "#     .success-box {\n",
    "#         background-color: #d4edda;\n",
    "#         color: #155724;\n",
    "#         padding: 1rem;\n",
    "#         border-radius: 8px;\n",
    "#         margin: 1rem 0;\n",
    "#     }\n",
    "# </style>\n",
    "# \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# @st.cache_data\n",
    "# def load_models():\n",
    "#     \"\"\"Load pre-trained models and data\"\"\"\n",
    "#     models_path = \"models\"\n",
    "    \n",
    "#     try:\n",
    "#         # Load scalers\n",
    "#         with open(f\"{models_path}/scalers.pkl\", 'rb') as f:\n",
    "#             scalers = pickle.load(f)\n",
    "        \n",
    "#         # Load label encoders\n",
    "#         with open(f\"{models_path}/label_encoders.pkl\", 'rb') as f:\n",
    "#             encoders = pickle.load(f)\n",
    "        \n",
    "#         # Load feature names\n",
    "#         with open(f\"{models_path}/feature_names.pkl\", 'rb') as f:\n",
    "#             feature_names = pickle.load(f)\n",
    "        \n",
    "#         # Load branch performance data\n",
    "#         with open(f\"{models_path}/branch_performance.pkl\", 'rb') as f:\n",
    "#             branch_performance = pickle.load(f)\n",
    "        \n",
    "#         # Load models\n",
    "#         models = {}\n",
    "#         model_files = [f for f in os.listdir(models_path) if f.endswith('_model.pkl')]\n",
    "#         for model_file in model_files:\n",
    "#             category = model_file.replace('_model.pkl', '').replace('_', ' ')\n",
    "#             with open(f\"{models_path}/{model_file}\", 'rb') as f:\n",
    "#                 models[category] = pickle.load(f)\n",
    "        \n",
    "#         return models, scalers, encoders, feature_names, branch_performance\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         st.error(f\"Error loading models: {e}\")\n",
    "#         return None, None, None, None, None\n",
    "\n",
    "# def predict_single_location(models, scalers, encoders, feature_names, branch_performance, \n",
    "#                           latitude, longitude, category, aov_estimate=None):\n",
    "#     \"\"\"Predict performance for a single location\"\"\"\n",
    "    \n",
    "#     if category not in models:\n",
    "#         return None\n",
    "    \n",
    "#     model = models[category]\n",
    "#     scaler = scalers[category]\n",
    "    \n",
    "#     # Get category benchmark data\n",
    "#     cat_data = branch_performance[branch_performance['Category'] == category]\n",
    "    \n",
    "#     # Use provided AOV or category median\n",
    "#     if aov_estimate is None:\n",
    "#         aov_estimate = cat_data['aov_2024'].median() if len(cat_data) > 0 else 75000\n",
    "    \n",
    "#     # Calculate derived features\n",
    "#     estimated_daily_transactions = 15  # Conservative estimate\n",
    "#     revenue_per_transaction = aov_estimate * 1.2\n",
    "#     high_value_customer = 1 if aov_estimate > cat_data['aov_2024'].median() else 0\n",
    "#     high_volume_branch = 0  # Conservative for new location\n",
    "    \n",
    "#     # Default subdistrict encoding (most common)\n",
    "#     subdistrict_encoded = 0\n",
    "    \n",
    "#     # Create feature vector matching training features\n",
    "#     features = np.array([[\n",
    "#         latitude,\n",
    "#         longitude,\n",
    "#         aov_estimate,\n",
    "#         estimated_daily_transactions,\n",
    "#         revenue_per_transaction,\n",
    "#         high_value_customer,\n",
    "#         high_volume_branch,\n",
    "#         subdistrict_encoded\n",
    "#     ]])\n",
    "    \n",
    "#     # Scale features\n",
    "#     features_scaled = scaler.transform(features)\n",
    "    \n",
    "#     # Make prediction\n",
    "#     predicted_monthly_gtv = model.predict(features_scaled)[0]\n",
    "    \n",
    "#     return {\n",
    "#         'latitude': latitude,\n",
    "#         'longitude': longitude,\n",
    "#         'category': category,\n",
    "#         'predicted_monthly_gtv': predicted_monthly_gtv,\n",
    "#         'predicted_annual_gtv': predicted_monthly_gtv * 12,\n",
    "#         'input_aov': aov_estimate,\n",
    "#         'estimated_daily_transactions': estimated_daily_transactions\n",
    "#     }\n",
    "\n",
    "# def calculate_area_demographics(lat, lng, branch_performance):\n",
    "#     \"\"\"Calculate area-specific demographics and business factors\"\"\"\n",
    "    \n",
    "#     # Calculate distance to major business centers (Jakarta Selatan landmarks)\n",
    "#     business_centers = [\n",
    "#         (-6.2088, 106.8456),  # Sudirman CBD\n",
    "#         (-6.2297, 106.8230),  # Senopati\n",
    "#         (-6.2614, 106.7814),  # Kebayoran Baru\n",
    "#         (-6.3002, 106.8197),  # Pondok Indah\n",
    "#         (-6.2751, 106.8095),  # Blok M\n",
    "#     ]\n",
    "    \n",
    "#     # Distance to nearest business center (smaller = better)\n",
    "#     min_distance_to_cbd = min([\n",
    "#         np.sqrt((lat - cbd_lat)**2 + (lng - cbd_lng)**2) \n",
    "#         for cbd_lat, cbd_lng in business_centers\n",
    "#     ])\n",
    "    \n",
    "#     # Area traffic factor (closer to CBD = higher traffic)\n",
    "#     traffic_factor = max(0.5, 1.0 - (min_distance_to_cbd * 10))  # Scale factor\n",
    "    \n",
    "#     # Calculate local branch density in radius\n",
    "#     nearby_branches = 0\n",
    "#     radius = 0.01  # ~1km radius\n",
    "#     for _, branch in branch_performance.iterrows():\n",
    "#         dist = np.sqrt((lat - branch['latitude'])**2 + (lng - branch['longitude'])**2)\n",
    "#         if dist <= radius:\n",
    "#             nearby_branches += 1\n",
    "    \n",
    "#     # Market saturation factor\n",
    "#     market_saturation = min(nearby_branches / 10.0, 0.8)  # Max 80% saturation\n",
    "    \n",
    "#     # Area prosperity factor (based on distance to upscale areas)\n",
    "#     upscale_areas = [\n",
    "#         (-6.2297, 106.8230),  # Senopati\n",
    "#         (-6.3002, 106.8197),  # Pondok Indah\n",
    "#         (-6.2614, 106.7814),  # Kebayoran Baru\n",
    "#     ]\n",
    "    \n",
    "#     min_distance_to_upscale = min([\n",
    "#         np.sqrt((lat - area_lat)**2 + (lng - area_lng)**2) \n",
    "#         for area_lat, area_lng in upscale_areas\n",
    "#     ])\n",
    "    \n",
    "#     prosperity_factor = max(0.7, 1.3 - (min_distance_to_upscale * 8))\n",
    "    \n",
    "#     return {\n",
    "#         'traffic_factor': traffic_factor,\n",
    "#         'market_saturation': market_saturation,\n",
    "#         'prosperity_factor': prosperity_factor,\n",
    "#         'nearby_branches': nearby_branches,\n",
    "#         'distance_to_cbd': min_distance_to_cbd\n",
    "#     }\n",
    "\n",
    "# def find_optimal_locations(models, scalers, encoders, feature_names, branch_performance, \n",
    "#                           category, num_locations=10):\n",
    "#     \"\"\"Find optimal locations for a category with dynamic location-specific features\"\"\"\n",
    "    \n",
    "#     if category not in models:\n",
    "#         return None\n",
    "    \n",
    "#     # Get existing successful locations for this category\n",
    "#     cat_data = branch_performance[branch_performance['Category'] == category]\n",
    "    \n",
    "#     if len(cat_data) == 0:\n",
    "#         return None\n",
    "    \n",
    "#     # Define grid of potential locations in Jakarta Selatan (increased resolution)\n",
    "#     lat_min, lat_max = -6.4, -6.1\n",
    "#     lng_min, lng_max = 106.7, 106.9\n",
    "    \n",
    "#     # Create finer grid for more location variety\n",
    "#     lat_grid = np.linspace(lat_min, lat_max, 30)  # Increased from 20 to 30\n",
    "#     lng_grid = np.linspace(lng_min, lng_max, 30)  # Increased from 20 to 30\n",
    "    \n",
    "#     predictions = []\n",
    "    \n",
    "#     # Get category stats for dynamic calculations\n",
    "#     category_stats = {\n",
    "#         'median_aov': cat_data['aov_2024'].median(),\n",
    "#         'q75_aov': cat_data['aov_2024'].quantile(0.75),\n",
    "#         'q25_aov': cat_data['aov_2024'].quantile(0.25),\n",
    "#         'median_daily_transactions': cat_data['estimated_daily_transactions'].median() if 'estimated_daily_transactions' in cat_data.columns else 15,\n",
    "#         'max_daily_transactions': cat_data['estimated_daily_transactions'].max() if 'estimated_daily_transactions' in cat_data.columns else 50\n",
    "#     }\n",
    "    \n",
    "#     for lat in lat_grid:\n",
    "#         for lng in lng_grid:\n",
    "#             # Calculate location-specific demographics\n",
    "#             demographics = calculate_area_demographics(lat, lng, branch_performance)\n",
    "            \n",
    "#             # Dynamic AOV based on area prosperity\n",
    "#             dynamic_aov = category_stats['median_aov'] * demographics['prosperity_factor']\n",
    "#             dynamic_aov = np.clip(dynamic_aov, category_stats['q25_aov'], category_stats['q75_aov'] * 1.2)\n",
    "            \n",
    "#             # Dynamic daily transactions based on traffic and saturation\n",
    "#             base_transactions = category_stats['median_daily_transactions']\n",
    "#             dynamic_daily_transactions = base_transactions * demographics['traffic_factor'] * (1 - demographics['market_saturation'])\n",
    "#             dynamic_daily_transactions = max(5, min(dynamic_daily_transactions, category_stats['max_daily_transactions']))\n",
    "            \n",
    "#             # Calculate distance to competitors for this specific category\n",
    "#             competitor_distances = []\n",
    "#             for _, competitor in cat_data.iterrows():\n",
    "#                 dist = np.sqrt((lat - competitor['latitude'])**2 + \n",
    "#                              (lng - competitor['longitude'])**2)\n",
    "#                 competitor_distances.append(dist)\n",
    "            \n",
    "#             nearest_competitor_distance = min(competitor_distances) if competitor_distances else 1.0\n",
    "            \n",
    "#             # Make prediction with dynamic features\n",
    "#             prediction = predict_single_location_dynamic(\n",
    "#                 models, scalers, encoders, feature_names, branch_performance,\n",
    "#                 lat, lng, category, dynamic_aov, dynamic_daily_transactions, demographics\n",
    "#             )\n",
    "            \n",
    "#             if prediction:\n",
    "#                 # Enhanced opportunity score calculation\n",
    "#                 base_score = prediction['predicted_monthly_gtv']\n",
    "                \n",
    "#                 # Bonus for distance from competitors\n",
    "#                 competition_bonus = min(nearest_competitor_distance * 100000, base_score * 0.3)\n",
    "                \n",
    "#                 # Penalty for market saturation\n",
    "#                 saturation_penalty = base_score * demographics['market_saturation'] * 0.2\n",
    "                \n",
    "#                 # Bonus for high traffic areas\n",
    "#                 traffic_bonus = base_score * (demographics['traffic_factor'] - 1) * 0.5\n",
    "                \n",
    "#                 opportunity_score = base_score + competition_bonus - saturation_penalty + traffic_bonus\n",
    "                \n",
    "#                 prediction.update({\n",
    "#                     'nearest_competitor_distance': nearest_competitor_distance,\n",
    "#                     'opportunity_score': opportunity_score,\n",
    "#                     'traffic_factor': demographics['traffic_factor'],\n",
    "#                     'market_saturation': demographics['market_saturation'],\n",
    "#                     'prosperity_factor': demographics['prosperity_factor'],\n",
    "#                     'nearby_branches_all_categories': demographics['nearby_branches'],\n",
    "#                     'distance_to_cbd': demographics['distance_to_cbd'],\n",
    "#                     'dynamic_aov_used': dynamic_aov,\n",
    "#                     'dynamic_transactions_used': dynamic_daily_transactions\n",
    "#                 })\n",
    "                \n",
    "#                 predictions.append(prediction)\n",
    "    \n",
    "#     # Sort by opportunity score and return top locations\n",
    "#     predictions.sort(key=lambda x: x['opportunity_score'], reverse=True)\n",
    "    \n",
    "#     # Remove very similar locations (deduplication)\n",
    "#     filtered_predictions = []\n",
    "#     min_distance_between_locations = 0.005  # Minimum distance between recommended locations\n",
    "    \n",
    "#     for pred in predictions:\n",
    "#         too_close = False\n",
    "#         for existing in filtered_predictions:\n",
    "#             dist = np.sqrt((pred['latitude'] - existing['latitude'])**2 + \n",
    "#                           (pred['longitude'] - existing['longitude'])**2)\n",
    "#             if dist < min_distance_between_locations:\n",
    "#                 too_close = True\n",
    "#                 break\n",
    "        \n",
    "#         if not too_close:\n",
    "#             filtered_predictions.append(pred)\n",
    "            \n",
    "#         if len(filtered_predictions) >= num_locations:\n",
    "#             break\n",
    "    \n",
    "#     return filtered_predictions\n",
    "\n",
    "# def predict_single_location_dynamic(models, scalers, encoders, feature_names, branch_performance, \n",
    "#                                    latitude, longitude, category, dynamic_aov, dynamic_daily_transactions, demographics):\n",
    "#     \"\"\"Enhanced prediction with dynamic location-specific features\"\"\"\n",
    "    \n",
    "#     if category not in models:\n",
    "#         return None\n",
    "    \n",
    "#     model = models[category]\n",
    "#     scaler = scalers[category]\n",
    "    \n",
    "#     # Calculate derived features with dynamic values\n",
    "#     revenue_per_transaction = dynamic_aov * 1.1  # Reduced multiplier for realism\n",
    "    \n",
    "#     # Dynamic customer value based on area prosperity\n",
    "#     high_value_customer = 1 if (dynamic_aov * demographics['prosperity_factor']) > 100000 else 0\n",
    "    \n",
    "#     # Volume estimation based on traffic and competition\n",
    "#     high_volume_branch = 1 if dynamic_daily_transactions > 20 else 0\n",
    "    \n",
    "#     # Default subdistrict encoding (could be enhanced with actual mapping)\n",
    "#     subdistrict_encoded = 0\n",
    "    \n",
    "#     # Create feature vector matching training features\n",
    "#     features = np.array([[\n",
    "#         latitude,\n",
    "#         longitude,\n",
    "#         dynamic_aov,\n",
    "#         dynamic_daily_transactions,\n",
    "#         revenue_per_transaction,\n",
    "#         high_value_customer,\n",
    "#         high_volume_branch,\n",
    "#         subdistrict_encoded\n",
    "#     ]])\n",
    "    \n",
    "#     # Scale features\n",
    "#     features_scaled = scaler.transform(features)\n",
    "    \n",
    "#     # Make prediction\n",
    "#     predicted_monthly_gtv = model.predict(features_scaled)[0]\n",
    "    \n",
    "#     # Apply location-specific adjustments\n",
    "#     location_adjustment = demographics['traffic_factor'] * demographics['prosperity_factor'] * (1 - demographics['market_saturation'] * 0.3)\n",
    "#     adjusted_prediction = predicted_monthly_gtv * location_adjustment\n",
    "    \n",
    "#     # Ensure realistic bounds\n",
    "#     adjusted_prediction = max(adjusted_prediction, 10000000)  # Min 10 million/month\n",
    "#     adjusted_prediction = min(adjusted_prediction, 500000000)  # Max 500 million/month\n",
    "    \n",
    "#     return {\n",
    "#         'latitude': latitude,\n",
    "#         'longitude': longitude,\n",
    "#         'category': category,\n",
    "#         'predicted_monthly_gtv': adjusted_prediction,\n",
    "#         'predicted_annual_gtv': adjusted_prediction * 12,\n",
    "#         'input_aov': dynamic_aov,\n",
    "#         'estimated_daily_transactions': dynamic_daily_transactions,\n",
    "#         'location_adjustment_factor': location_adjustment\n",
    "#     }\n",
    "\n",
    "# def create_location_map(predictions, existing_branches=None):\n",
    "#     \"\"\"Create interactive map with predictions\"\"\"\n",
    "    \n",
    "#     if not predictions:\n",
    "#         return None\n",
    "    \n",
    "#     # Create base map\n",
    "#     center_lat = -6.25\n",
    "#     center_lng = 106.8\n",
    "    \n",
    "#     m = folium.Map(\n",
    "#         location=[center_lat, center_lng],\n",
    "#         zoom_start=12,\n",
    "#         tiles='OpenStreetMap'\n",
    "#     )\n",
    "    \n",
    "#     # Add predicted locations\n",
    "#     colors = ['red', 'orange', 'yellow', 'green', 'blue', 'purple', 'pink', 'gray', 'black', 'lightred']\n",
    "    \n",
    "#     for i, pred in enumerate(predictions):\n",
    "#         color = colors[i % len(colors)]\n",
    "        \n",
    "#         popup_text = f\"\"\"\n",
    "#         <b>Rank {i+1} - {pred['category']}</b><br>\n",
    "#         Coordinates: ({pred['latitude']:.4f}, {pred['longitude']:.4f})<br>\n",
    "#         <b>Predicted Monthly Revenue: Rp {pred['predicted_monthly_gtv']:,.0f}</b><br>\n",
    "#         <b>Predicted Annual Revenue: Rp {pred['predicted_annual_gtv']:,.0f}</b><br>\n",
    "#         Est. Daily Transactions: {pred['estimated_daily_transactions']:.1f}<br>\n",
    "#         Dynamic AOV: Rp {pred.get('dynamic_aov_used', pred['input_aov']):,.0f}<br>\n",
    "#         Traffic Factor: {pred.get('traffic_factor', 1.0):.2f}<br>\n",
    "#         Market Saturation: {pred.get('market_saturation', 0.0):.1%}<br>\n",
    "#         Distance to CBD: {pred.get('distance_to_cbd', 0.0):.3f}<br>\n",
    "#         Opportunity Score: {pred.get('opportunity_score', 0):,.0f}\n",
    "#         \"\"\"\n",
    "        \n",
    "#         folium.Marker(\n",
    "#             [pred['latitude'], pred['longitude']],\n",
    "#             popup=folium.Popup(popup_text, max_width=300),\n",
    "#             tooltip=f\"Rank {i+1}: Rp {pred['predicted_monthly_gtv']:,.0f}/month\",\n",
    "#             icon=folium.Icon(color=color, icon='cutlery', prefix='fa')\n",
    "#         ).add_to(m)\n",
    "    \n",
    "#     # Add existing branches if provided\n",
    "#     if existing_branches is not None:\n",
    "#         for _, branch in existing_branches.iterrows():\n",
    "#             folium.CircleMarker(\n",
    "#                 [branch['latitude'], branch['longitude']],\n",
    "#                 radius=5,\n",
    "#                 popup=f\"Existing: {branch['Category']}<br>Monthly GTV: Rp {branch['monthly_gtv']:,.0f}\",\n",
    "#                 color='black',\n",
    "#                 weight=2,\n",
    "#                 fillColor='white',\n",
    "#                 fillOpacity=0.7\n",
    "#             ).add_to(m)\n",
    "    \n",
    "#     return m\n",
    "\n",
    "# def create_revenue_comparison_chart(predictions):\n",
    "#     \"\"\"Create revenue comparison chart\"\"\"\n",
    "    \n",
    "#     if not predictions:\n",
    "#         return None\n",
    "    \n",
    "#     df_chart = pd.DataFrame(predictions)\n",
    "#     df_chart['rank'] = range(1, len(df_chart) + 1)\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "    \n",
    "#     # Monthly revenue bars\n",
    "#     fig.add_trace(go.Bar(\n",
    "#         x=df_chart['rank'],\n",
    "#         y=df_chart['predicted_monthly_gtv'],\n",
    "#         name='Monthly Revenue',\n",
    "#         text=[f\"Rp {val:,.0f}\" for val in df_chart['predicted_monthly_gtv']],\n",
    "#         textposition='auto',\n",
    "#         marker_color='lightblue'\n",
    "#     ))\n",
    "    \n",
    "#     # Opportunity score line (if available)\n",
    "#     if 'opportunity_score' in df_chart.columns:\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             x=df_chart['rank'],\n",
    "#             y=df_chart['opportunity_score'],\n",
    "#             mode='lines+markers',\n",
    "#             name='Opportunity Score',\n",
    "#             yaxis='y2',\n",
    "#             line=dict(color='red', width=2),\n",
    "#             marker=dict(size=8)\n",
    "#         ))\n",
    "        \n",
    "#         fig.update_layout(\n",
    "#             yaxis2=dict(\n",
    "#                 title=\"Opportunity Score\",\n",
    "#                 overlaying='y',\n",
    "#                 side='right'\n",
    "#             )\n",
    "#         )\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Revenue Predictions Comparison',\n",
    "#         xaxis_title=\"Location Rank\",\n",
    "#         yaxis_title=\"Predicted Monthly Revenue (Rp)\",\n",
    "#         height=500,\n",
    "#         showlegend=True\n",
    "#     )\n",
    "    \n",
    "#     return fig\n",
    "\n",
    "# def main():\n",
    "#     # Header\n",
    "#     st.markdown('<h1 class=\"main-header\">üçΩÔ∏è Restaurant Location ML System</h1>', unsafe_allow_html=True)\n",
    "#     st.markdown('<p style=\"text-align: center; font-size: 1.2rem; color: #666;\">Optimal Restaurant Location Prediction for Jakarta Selatan</p>', unsafe_allow_html=True)\n",
    "    \n",
    "#     # Load models\n",
    "#     with st.spinner(\"Loading ML models...\"):\n",
    "#         models, scalers, encoders, feature_names, branch_performance = load_models()\n",
    "    \n",
    "#     if models is None:\n",
    "#         st.error(\"‚ùå Could not load trained models. Please ensure models are trained and saved.\")\n",
    "#         st.info(\"üìù Run the training script first to generate models.\")\n",
    "#         st.code(\"\"\"\n",
    "# # Run this first:\n",
    "# python restaurant_ml_training.py\n",
    "#         \"\"\")\n",
    "#         return\n",
    "    \n",
    "#     st.success(f\"‚úÖ Successfully loaded {len(models)} trained models!\")\n",
    "    \n",
    "#     # Sidebar navigation\n",
    "#     st.sidebar.title(\"üß≠ Navigation\")\n",
    "#     page = st.sidebar.selectbox(\n",
    "#         \"Select Analysis Type\",\n",
    "#         [\"üéØ Single Location Prediction\", \"üó∫Ô∏è Optimal Location Finder\", \"üìä Model Performance\", \"üìà Data Insights\"]\n",
    "#     )\n",
    "    \n",
    "#     if page == \"üéØ Single Location Prediction\":\n",
    "#         st.header(\"üéØ Single Location Prediction\")\n",
    "#         st.write(\"Predict revenue for a specific location and restaurant category.\")\n",
    "        \n",
    "#         col1, col2 = st.columns([2, 1])\n",
    "        \n",
    "#         with col1:\n",
    "#             # Input parameters\n",
    "#             st.subheader(\"üìç Location Parameters\")\n",
    "            \n",
    "#             # Category selection\n",
    "#             available_categories = list(models.keys())\n",
    "#             selected_category = st.selectbox(\n",
    "#                 \"Restaurant Category\",\n",
    "#                 available_categories,\n",
    "#                 help=\"Select the type of restaurant\"\n",
    "#             )\n",
    "            \n",
    "#             # Location inputs\n",
    "#             col_lat, col_lng = st.columns(2)\n",
    "#             with col_lat:\n",
    "#                 latitude = st.number_input(\n",
    "#                     \"Latitude\", \n",
    "#                     value=-6.2608, \n",
    "#                     min_value=-6.4, \n",
    "#                     max_value=-6.1,\n",
    "#                     step=0.0001,\n",
    "#                     format=\"%.4f\"\n",
    "#                 )\n",
    "            \n",
    "#             with col_lng:\n",
    "#                 longitude = st.number_input(\n",
    "#                     \"Longitude\", \n",
    "#                     value=106.7811, \n",
    "#                     min_value=106.7, \n",
    "#                     max_value=106.9,\n",
    "#                     step=0.0001,\n",
    "#                     format=\"%.4f\"\n",
    "#                 )\n",
    "            \n",
    "#             # AOV input\n",
    "#             cat_data = branch_performance[branch_performance['Category'] == selected_category]\n",
    "#             default_aov = int(cat_data['aov_2024'].median()) if len(cat_data) > 0 else 75000\n",
    "            \n",
    "#             aov_estimate = st.number_input(\n",
    "#                 \"Expected Average Order Value (AOV)\",\n",
    "#                 value=default_aov,\n",
    "#                 min_value=10000,\n",
    "#                 max_value=500000,\n",
    "#                 step=5000,\n",
    "#                 help=f\"Default is median AOV for {selected_category}: Rp {default_aov:,}\"\n",
    "#             )\n",
    "            \n",
    "#             # Predict button\n",
    "#             if st.button(\"üîÆ Predict Revenue\", type=\"primary\", use_container_width=True):\n",
    "#                 with st.spinner(\"Generating prediction...\"):\n",
    "#                     prediction = predict_single_location(\n",
    "#                         models, scalers, encoders, feature_names, branch_performance,\n",
    "#                         latitude, longitude, selected_category, aov_estimate\n",
    "#                     )\n",
    "                    \n",
    "#                     if prediction:\n",
    "#                         st.session_state.single_prediction = prediction\n",
    "#                         st.success(\"‚úÖ Prediction completed!\")\n",
    "#                     else:\n",
    "#                         st.error(\"‚ùå Failed to generate prediction\")\n",
    "        \n",
    "#         with col2:\n",
    "#             # Display results\n",
    "#             if hasattr(st.session_state, 'single_prediction'):\n",
    "#                 pred = st.session_state.single_prediction\n",
    "                \n",
    "#                 st.subheader(\"üìä Prediction Results\")\n",
    "                \n",
    "#                 # Metrics\n",
    "#                 st.metric(\n",
    "#                     \"üí∞ Monthly Revenue\", \n",
    "#                     f\"Rp {pred['predicted_monthly_gtv']:,.0f}\"\n",
    "#                 )\n",
    "                \n",
    "#                 st.metric(\n",
    "#                     \"üìÖ Annual Revenue\", \n",
    "#                     f\"Rp {pred['predicted_annual_gtv']:,.0f}\"\n",
    "#                 )\n",
    "                \n",
    "#                 st.metric(\n",
    "#                     \"üõí Daily Transactions\", \n",
    "#                     f\"{pred['estimated_daily_transactions']}\"\n",
    "#                 )\n",
    "                \n",
    "#                 st.metric(\n",
    "#                     \"üí≥ Input AOV\", \n",
    "#                     f\"Rp {pred['input_aov']:,.0f}\"\n",
    "#                 )\n",
    "                \n",
    "#                 # Create simple map for single location\n",
    "#                 simple_map = folium.Map(\n",
    "#                     location=[pred['latitude'], pred['longitude']],\n",
    "#                     zoom_start=15\n",
    "#                 )\n",
    "                \n",
    "#                 folium.Marker(\n",
    "#                     [pred['latitude'], pred['longitude']],\n",
    "#                     popup=f\"Predicted Monthly Revenue: Rp {pred['predicted_monthly_gtv']:,.0f}\",\n",
    "#                     tooltip=\"Predicted Location\",\n",
    "#                     icon=folium.Icon(color='red', icon='cutlery', prefix='fa')\n",
    "#                 ).add_to(simple_map)\n",
    "                \n",
    "#                 st.subheader(\"üìç Location Map\")\n",
    "#                 st_folium(simple_map, width=350, height=300)\n",
    "    \n",
    "#     elif page == \"üó∫Ô∏è Optimal Location Finder\":\n",
    "#         st.header(\"üó∫Ô∏è Optimal Location Finder\")\n",
    "#         st.write(\"Find the best locations for your restaurant category across Jakarta Selatan.\")\n",
    "        \n",
    "#         # Parameters\n",
    "#         col1, col2 = st.columns([3, 1])\n",
    "        \n",
    "#         with col2:\n",
    "#             st.subheader(\"‚öôÔ∏è Search Parameters\")\n",
    "            \n",
    "#             available_categories = list(models.keys())\n",
    "#             selected_category = st.selectbox(\n",
    "#                 \"Restaurant Category\",\n",
    "#                 available_categories\n",
    "#             )\n",
    "            \n",
    "#             num_locations = st.slider(\n",
    "#                 \"Number of locations to find\",\n",
    "#                 min_value=5,\n",
    "#                 max_value=15,\n",
    "#                 value=10\n",
    "#             )\n",
    "            \n",
    "#             show_existing = st.checkbox(\n",
    "#                 \"Show existing branches\",\n",
    "#                 value=True,\n",
    "#                 help=\"Display existing branches of the same category on the map\"\n",
    "#             )\n",
    "            \n",
    "#             if st.button(\"üîç Find Optimal Locations\", type=\"primary\", use_container_width=True):\n",
    "#                 with st.spinner(f\"Analyzing optimal locations for {selected_category}...\"):\n",
    "#                     predictions = find_optimal_locations(\n",
    "#                         models, scalers, encoders, feature_names, branch_performance,\n",
    "#                         selected_category, num_locations\n",
    "#                     )\n",
    "                    \n",
    "#                     if predictions:\n",
    "#                         st.session_state.optimal_predictions = predictions\n",
    "#                         st.session_state.optimal_category = selected_category\n",
    "#                         st.session_state.show_existing = show_existing\n",
    "#                         st.success(f\"‚úÖ Found {len(predictions)} optimal locations!\")\n",
    "#                     else:\n",
    "#                         st.error(\"‚ùå Failed to find optimal locations\")\n",
    "        \n",
    "#         with col1:\n",
    "#             # Display results\n",
    "#             if hasattr(st.session_state, 'optimal_predictions'):\n",
    "#                 predictions = st.session_state.optimal_predictions\n",
    "#                 category = st.session_state.optimal_category\n",
    "#                 show_existing = st.session_state.show_existing\n",
    "                \n",
    "#                 st.subheader(f\"üèÜ Top Locations for {category}\")\n",
    "                \n",
    "#                 # Create results table\n",
    "#                 df_results = pd.DataFrame(predictions)\n",
    "#                 df_results['Rank'] = range(1, len(df_results) + 1)\n",
    "#                 df_results['Monthly Revenue'] = df_results['predicted_monthly_gtv'].apply(lambda x: f\"Rp {x:,.0f}\")\n",
    "#                 df_results['Annual Revenue'] = df_results['predicted_annual_gtv'].apply(lambda x: f\"Rp {x:,.0f}\")\n",
    "#                 df_results['Opportunity Score'] = df_results['opportunity_score'].apply(lambda x: f\"{x:,.0f}\")\n",
    "#                 df_results['Traffic Factor'] = df_results['traffic_factor'].apply(lambda x: f\"{x:.2f}\")\n",
    "#                 df_results['Market Saturation'] = df_results['market_saturation'].apply(lambda x: f\"{x:.1%}\")\n",
    "#                 df_results['Distance to CBD'] = df_results['distance_to_cbd'].apply(lambda x: f\"{x:.3f}\")\n",
    "                \n",
    "#                 display_cols = ['Rank', 'latitude', 'longitude', 'Monthly Revenue', 'Annual Revenue', \n",
    "#                                'Traffic Factor', 'Market Saturation', 'Distance to CBD', 'Opportunity Score']\n",
    "#                 column_names = ['Rank', 'Latitude', 'Longitude', 'Monthly Revenue', 'Annual Revenue', \n",
    "#                                'Traffic Factor', 'Saturation', 'Distance to CBD', 'Opportunity Score']\n",
    "                \n",
    "#                 df_show = df_results[display_cols].copy()\n",
    "#                 df_show.columns = column_names\n",
    "                \n",
    "#                 st.dataframe(df_show, use_container_width=True, hide_index=True)\n",
    "                \n",
    "#                 # Charts and map\n",
    "#                 st.subheader(\"üìä Analysis\")\n",
    "                \n",
    "#                 # Revenue chart\n",
    "#                 fig = create_revenue_comparison_chart(predictions)\n",
    "#                 if fig:\n",
    "#                     st.plotly_chart(fig, use_container_width=True)\n",
    "                \n",
    "#                 # Map\n",
    "#                 st.subheader(\"üó∫Ô∏è Location Map\")\n",
    "#                 existing_branches = None\n",
    "#                 if show_existing:\n",
    "#                     existing_branches = branch_performance[branch_performance['Category'] == category]\n",
    "                \n",
    "#                 location_map = create_location_map(predictions, existing_branches)\n",
    "#                 if location_map:\n",
    "#                     st_folium(location_map, width=700, height=500)\n",
    "    \n",
    "#     elif page == \"üìä Model Performance\":\n",
    "#         st.header(\"üìä Model Performance Dashboard\")\n",
    "        \n",
    "#         # Model overview\n",
    "#         st.subheader(\"ü§ñ Available Models\")\n",
    "        \n",
    "#         model_data = []\n",
    "#         for category in models.keys():\n",
    "#             cat_branches = branch_performance[branch_performance['Category'] == category]\n",
    "#             model_data.append({\n",
    "#                 'Category': category,\n",
    "#                 'Status': '‚úÖ Trained',\n",
    "#                 'Training Data Points': len(cat_branches),\n",
    "#                 'Avg Monthly Revenue': f\"Rp {cat_branches['monthly_gtv'].mean():,.0f}\" if len(cat_branches) > 0 else \"N/A\"\n",
    "#             })\n",
    "        \n",
    "#         df_models = pd.DataFrame(model_data)\n",
    "#         st.dataframe(df_models, use_container_width=True, hide_index=True)\n",
    "        \n",
    "#         # Feature importance info\n",
    "#         st.subheader(\"üéØ Model Features\")\n",
    "#         st.write(\"Models use the following features for prediction:\")\n",
    "        \n",
    "#         if feature_names:\n",
    "#             feature_info = {\n",
    "#                 'Feature': feature_names,\n",
    "#                 'Description': [\n",
    "#                     'Latitude coordinate',\n",
    "#                     'Longitude coordinate', \n",
    "#                     'Average Order Value',\n",
    "#                     'Estimated daily transactions',\n",
    "#                     'Revenue per transaction',\n",
    "#                     'High value customer indicator',\n",
    "#                     'High volume branch indicator',\n",
    "#                     'Subdistrict encoding'\n",
    "#                 ]\n",
    "#             }\n",
    "            \n",
    "#             st.dataframe(pd.DataFrame(feature_info), use_container_width=True, hide_index=True)\n",
    "        \n",
    "#         st.info(\"üí° Model performance metrics (R¬≤, MAE, RMSE) are displayed during training.\")\n",
    "    \n",
    "#     elif page == \"üìà Data Insights\":\n",
    "#         st.header(\"üìà Data Insights\")\n",
    "        \n",
    "#         # Overview metrics\n",
    "#         col1, col2, col3, col4 = st.columns(4)\n",
    "        \n",
    "#         with col1:\n",
    "#             st.metric(\"üè™ Total Branches\", len(branch_performance))\n",
    "        \n",
    "#         with col2:\n",
    "#             st.metric(\"üè∑Ô∏è Categories\", branch_performance['Category'].nunique())\n",
    "        \n",
    "#         with col3:\n",
    "#             st.metric(\"üìç Subdistricts\", branch_performance['subdistrictName'].nunique())\n",
    "        \n",
    "#         with col4:\n",
    "#             avg_revenue = branch_performance['monthly_gtv'].mean()\n",
    "#             st.metric(\"üí∞ Avg Monthly Revenue\", f\"Rp {avg_revenue:,.0f}\")\n",
    "        \n",
    "#         # Revenue distribution\n",
    "#         st.subheader(\"üí∞ Revenue Distribution\")\n",
    "        \n",
    "#         fig_hist = px.histogram(\n",
    "#             branch_performance,\n",
    "#             x='monthly_gtv',\n",
    "#             nbins=30,\n",
    "#             title=\"Distribution of Monthly Revenue\"\n",
    "#         )\n",
    "#         fig_hist.update_xaxis(title=\"Monthly Revenue (Rp)\")\n",
    "#         fig_hist.update_yaxis(title=\"Number of Branches\")\n",
    "        \n",
    "#         st.plotly_chart(fig_hist, use_container_width=True)\n",
    "        \n",
    "#         # Category performance\n",
    "#         st.subheader(\"üè∑Ô∏è Performance by Category\")\n",
    "        \n",
    "#         category_stats = branch_performance.groupby('Category').agg({\n",
    "#             'monthly_gtv': ['count', 'mean', 'median'],\n",
    "#             'aov_2024': 'mean'\n",
    "#         }).round(0)\n",
    "        \n",
    "#         category_stats.columns = ['Branch Count', 'Avg Revenue', 'Median Revenue', 'Avg AOV']\n",
    "#         category_stats = category_stats.sort_values('Avg Revenue', ascending=False).reset_index()\n",
    "        \n",
    "#         # Format currency columns\n",
    "#         for col in ['Avg Revenue', 'Median Revenue', 'Avg AOV']:\n",
    "#             category_stats[col] = category_stats[col].apply(lambda x: f\"Rp {x:,.0f}\")\n",
    "        \n",
    "#         st.dataframe(category_stats, use_container_width=True, hide_index=True)\n",
    "        \n",
    "#         # Geographic distribution\n",
    "#         st.subheader(\"üìç Geographic Distribution\")\n",
    "        \n",
    "#         district_stats = branch_performance.groupby('subdistrictName').agg({\n",
    "#             'monthly_gtv': ['count', 'mean'],\n",
    "#             'Category': 'nunique'\n",
    "#         }).round(0)\n",
    "        \n",
    "#         district_stats.columns = ['Branch Count', 'Avg Revenue', 'Category Variety']\n",
    "#         district_stats = district_stats.sort_values('Branch Count', ascending=False).head(10).reset_index()\n",
    "#         district_stats['Avg Revenue'] = district_stats['Avg Revenue'].apply(lambda x: f\"Rp {x:,.0f}\")\n",
    "        \n",
    "#         st.write(\"**Top 10 Subdistricts by Branch Count:**\")\n",
    "#         st.dataframe(district_stats, use_container_width=True, hide_index=True)\n",
    "        \n",
    "#         # Top performers\n",
    "#         st.subheader(\"üèÜ Top Performing Branches\")\n",
    "        \n",
    "#         top_branches = branch_performance.nlargest(10, 'monthly_gtv')[\n",
    "#             ['Category', 'subdistrictName', 'monthly_gtv', 'aov_2024']\n",
    "#         ].reset_index(drop=True)\n",
    "        \n",
    "#         top_branches['Rank'] = range(1, len(top_branches) + 1)\n",
    "#         top_branches['Monthly Revenue'] = top_branches['monthly_gtv'].apply(lambda x: f\"Rp {x:,.0f}\")\n",
    "#         top_branches['AOV'] = top_branches['aov_2024'].apply(lambda x: f\"Rp {x:,.0f}\")\n",
    "        \n",
    "#         display_top = top_branches[['Rank', 'Category', 'subdistrictName', 'Monthly Revenue', 'AOV']]\n",
    "#         display_top.columns = ['Rank', 'Category', 'Subdistrict', 'Monthly Revenue', 'AOV']\n",
    "        \n",
    "#         st.dataframe(display_top, use_container_width=True, hide_index=True)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac763c2-bac9-4992-ab7e-04a4b2d4036f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juanenv313",
   "language": "python",
   "name": "juanenv313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
